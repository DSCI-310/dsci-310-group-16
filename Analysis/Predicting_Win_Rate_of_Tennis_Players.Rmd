---
Title: "Predicting Win Rate of Tennis Players"
Authors: Ammar Bagharib, Miles Brodie
output: html_document
---

```{r, message=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, message=FALSE, warning=FALSE, echo = TRUE}
library(here)
source(here("Rscripts/load_libraries.R"))
source(here("Rscripts/clean_data.R"))
source(here("Rscripts/rmspe_functions.R"))
```

# Predicting the Win Rate of Tennis Players

## Introduction
### Background
Tennis is a popular, competitive sport played around the world. Tennis can be played in "singles" where there is only one person on each side of the net or "doubles" where there are teams of two. It can be played on a variety of surfaces such as grass, clay, or hard court (i.e. like a gym floor).

The association of tennis professionals, or ATP, organizes these tournaments and collects data on the players and the matches that take place.

### Our Question
Based on the career statistics of a tennis player, what will be their win rate?

### Our Dataset
We are using the "Game results for Top 500 Players from 2017-2019" dataset for our analysis. Each row in this dataset represents a singles match between two players. Each row contains player stats (e.g. age, height, rank) and match stats (break points, serve points, double faults etc.). We can use this data to determine the relationship between a player's stats and their win rate for this time period.

## Methods and Results
### Outline
We will first transform the dataset of tennis matches into a tidy dataset with only player stats. Next, we will look at the relationships between the different variables and win_rate to choose predictors for our regression models. To answer our predictive question, we will train both KNN and linear regression models and then compare to find the model type and predictors that give the lowest error. Once we have the best model, we will try to predict the win rate for a new player observation.

### Exploring the Data
The code below reads the CSV file.

```{r, message=FALSE, warning=FALSE, fig.width=13}
atp_df <- readr::read_csv(here("data/atp2017-2019-1.csv"))
tab_df(head(atp_df), title = "Table 1: Raw data table")
```


By mutating the data into nine predictors we can set KNN and Linear regression models to predict a player's career win rate. The predictors include:

| Variable | Explanation |
|:--- | :--- |
| Age (years) | Older players will have sustained more injuries and be less fit. |
| Height (cm) | Height can provide an advantage when serving. |
| Serve Points that were Aces (%) | Winning points on a serve indicates a strong serve. |
| First Serves (%) | The ratio of "first serve points" to "first serves made in" means a player's serve is more accurate |
| First Serves Won (%) | Strong and accurate first serves will lead to fewer double faults. |
| Second Serves Won (%) | Strong second serves means fewer lost points due to a slow serve. |
| Double Faults per Game (ratio) | Fewer double faults per game indicates accurate serving. |
| Breakpoints Saved (%) | Preventing breaks means a player wins the important points for winning the match |
| Rank Points |	Awarded to players by the ATP for winning matches |

*Table 2: List of Potential Predictors created for our data set*

The predictors related to serving are useful because a player has the most control over the match during the games when they are serving. For information on each type of serve stat see (Keith Prowse Editors) under references.

The stat on rank points is important because players earn a different number of rank points for each type of match (Nag, Utathya). Players may accumulate a lot of rank points by winning many lower ranked matches or by winning a few major matches, thus providing us insight to the wins a player may have.

The code below cleans and wrangles the raw data set into tidy form by grouping the observations by player. We mutate some statistics to percentages through ratios of the raw variables. We then obtain each player's "career stats" by joining observations in both winning and losing rounds to the player ID. This forms a data frame with each row representing an individual player.

### Data Transformation
```{r, message=FALSE, warning=FALSE,}
player_career <- player_career(atp_df)
tab_df(head(player_career), title = "Table 3: Mutated data table used for data processing")
```


We split the player career dataset into testing and training sets by a 75/25 split. We decided that this split ratio allowed for enough observations to be used to train our model while still having enough observations in our test set to evaluate its accuracy.


```{r}
# split the data set into training and testing set. The following exploratory data analysis uses only the training set
set.seed(20)
player_split <- initial_split(player_career, prop = 0.75, strata = win_rate)
player_train <- training(player_split)
player_test <- testing(player_split)

# csv_path <- paste0(here::here(), "/data")
# write.csv(player_train, paste(csv_path, "player_train.csv", sep = "/"))
# write.csv(player_test, paste(csv_path, "player_test.csv", sep = "/"))

```


The table below contains the means of each quantitative variable in the training set. This gives an idea of the average statistics for a given player, which is relevant for exploratory data analysis. It tells us what sort of values (or percentages) we can expect for each stat.

```{r}
# the means of the predictor variables we plan to use in our analysis
exploratory_data_analysis_table <- player_train %>%
    select(-player_id) %>%
    map_df(mean, na.rm = TRUE)
tab_df(exploratory_data_analysis_table, title = "Table 4: Mean Values for each Predictor Variable")
```

The code below produces a visualization which is also very useful in our exploratory data analysis. By using the function ggpairs, we can see the "big picture" of all the relationships between each pair of variables. This visualization helps us pick which variables have a relatively strong relationship with win rate, and thus will be effective in predictions.

```{r, fig.width=13, fig.height=10}
# select all quantitative predictors and visualize with ggpairs()
player_ggpairs <- player_train %>%
    select(-player_id) %>%
    ggpairs()

player_ggpairs
```
*Figure 1: Plot of All Predictor Relationships using ggpairs*


#### Model Selection

The first option for our model is K-NN regression for individual predictors with win_rate as the target value. In order to simplify the steps, we use a for loop to run the model on each predictor. The result is a table with 4 columns: the target variable, predictor, best k value (as chosen through cross validation), and RMSPE.

Warning! The for_loop iteration may take time.

```{r}
# create a list of predictors for the single variable regression
single_predictors <- list(
    'height','breakpoint_saved_pct','second_serve_win_pct','first_serve_pct',
    'first_serve_win_pct','age','mean_rank_points','ace_point_pct'
  )
```

### kknn single regression
```{r warning=FALSE}
tab_df(
  rmspe_bind(
    predictors_vector = single_predictors, 
    train_df = player_train, 
    test_df = player_test,
    method = "kknn", 
    mode = "single",
    target_variable = 'win_rate'
  ), 
  title = "kknn single regression"
)

```
 
 
### lm single regression
```{r warning=FALSE}
tab_df(
  rmspe_bind(
    predictors_vector = single_predictors, 
    train_df = player_train, 
    test_df = player_test,
    method = "lm", 
    mode = "single",
    target_variable = 'win_rate'
  ), 
  title = "lm single regression"
)
```


```{r}
# create a list of predictors for the multiple variable regression
multiple_predictors <- list(
    c("mean_rank_points", "first_serve_win_pct"),
    c("mean_rank_points", "height"),
    c("mean_rank_points", "first_serve_pct"),
    c("mean_rank_points", "first_serve_pct", "first_serve_win_pct"),
    c("mean_rank_points", "first_serve_pct", "height")
  )
```


### lm multiple regression
```{r warning=FALSE}
tab_df(
  rmspe_bind(
    predictors_vector = multiple_predictors, 
    train_df = player_train, 
    test_df = player_test,
    method = "lm", 
    mode = "multiple",
    target_variable = 'win_rate'
  ), 
  title = "lm multiple regression"
)
```


### kknn multiple regression
```{r warning=FALSE}
tab_df(
  rmspe_bind(
    predictors_vector = multiple_predictors, 
    train_df = player_train, 
    test_df = player_test,
    method = "kknn", 
    mode = "multiple",
    target_variable = 'win_rate'
  ), 
  title = "kknn multiple regression"
)
```

 

